# ğŸ“° Fake News Detection with NLP  
### *Built with TF-IDF, XGBoost, and Fine-Tuned BERT*

> Classifying political statements as **Fake** or **Real** using the LIAR dataset and state-of-the-art NLP techniques.

---

## ğŸš€ Live Demo

ğŸ”— **Try the App** â†’ [Fake News Detector on Hugging Face Spaces](https://huggingface.co/spaces/ShahOfData/shah_fake-news-detector)  
ğŸ’» **View Portfolio** â†’ [shahnekouei.com/projects](https://shahnekouei.com/projects)

---

## ğŸ§  Project Highlights

- âœ… Binary classification: Fake vs. Real  
- âœ… Preprocessing: lowercasing, stopword removal, punctuation cleanup  
- âœ… Models compared:
  - TF-IDF + Logistic Regression
  - TF-IDF + XGBoost
  - **BERT (fine-tuned and deployed)**
- âœ… Evaluation: accuracy, precision, recall, F1-score, confusion matrix  
- âœ… Deployment using Gradio + Hugging Face Spaces

---

## ğŸ“Š Dataset Summary

| Item              | Description |
|-------------------|-------------|
| ğŸ“š **Dataset**    | [LIAR Dataset (Wang, 2017)](https://www.cs.ucsb.edu/~william/data/liar_dataset.zip) |
| ğŸ§¾ **Size**       | ~12,800 labeled political statements |
| ğŸ—‚ï¸ **Labels**     | `true`, `mostly-true`, `half-true`, `barely-true`, `false`, `pants-fire` |
| ğŸ” **Remapping**  | Real (1): `true`, `mostly-true`, `half-true`<br>Fake (0): `false`, `barely-true`, `pants-fire` |

---

## ğŸ“ˆ Model Results

### âœ… Logistic Regression (TF-IDF)

**Test Set**
| Class | Precision | Recall | F1 Score |
|-------|-----------|--------|----------|
| Fake  | 0.59      | 0.39   | 0.47     |
| Real  | 0.62      | 0.79   | 0.70     |
> **Accuracy:** `0.61`

---

### âœ… XGBoost (TF-IDF)

**Test Set**
| Class | Precision | Recall | F1 Score |
|-------|-----------|--------|----------|
| Fake  | 0.53      | 0.61   | 0.57     |
| Real  | 0.66      | 0.57   | 0.61     |
> **Accuracy:** `0.5919`  
> **Confusion Matrix:** `[[340, 213], [304, 410]]`

---

### âœ… BERT (Fine-Tuned & Deployed)

**Test Set**
| Class | Precision | Recall | F1 Score |
|-------|-----------|--------|----------|
| Fake  | 0.58      | 0.58   | 0.58     |
| Real  | 0.67      | 0.67   | 0.67     |
> **Accuracy:** `0.63`  
> **Confusion Matrix:** `[[319, 234], [233, 481]]`

ğŸ–¼ï¸ *Confusion matrix visual available in the repo and demo.*

---

## ğŸ§© Project Structure

```bash
â”œâ”€â”€ fakeNewsCode.ipynb             # Training and evaluation notebook
â”œâ”€â”€ tfidf_vectorizer.pkl           # Saved TF-IDF vectorizer
â”œâ”€â”€ xgboost_model.pkl              # Trained XGBoost model
â”œâ”€â”€ hugging_face_fake_news/
â”‚   â””â”€â”€ model/                     # Fine-tuned BERT model files
â”œâ”€â”€ app.py                         # Gradio app script
â”œâ”€â”€ requirements.txt               # Dependencies for deployment
â”œâ”€â”€ README.md                      # Project documentation
